# 2019-07-10 Read From Screenshot

In this exploration, I want to learn more about how we can quickly test functions to read from screenshots. Reading from screenshots is the default method for a bot to learn about the current state of the (game)world. After the bot takes a screenshot of the game client, it applies functions to extract information out of the screenshot. A typical example is locating objects to interact with using mouse clicks.

Just as the bot development process in general, composing such an image processing function is an iterative process: Looking at an example image, I get an idea of how to model the pattern to search for and sketch the first approximation of the function. Then I run this function on the example image and review its output. Depending on the results I see there, I make changes to the image processing function. This cycle of testing and adjusting repeats until I have arrived at a version that produces the expected output for the example images.

Since bot developers run such tests hundreds of times per hour, I check that this process works smoothly.

Last weeks exploration ([2019-07-04.read-screenshot-from-file-and-configure-image-search](./../2019-07-04.read-screenshot-from-file-and-configure-image-search/app/src/Main.elm)) resulted in improvements in the same area: One of the results was a graphical user interface which allows a user to interactively load example screenshot and compose a function to search for objects in these screenshots.

What I miss in the result from last week: Support for testing any image processing function. The image pattern model developed there allows only to model a subset of these functions. After completing the last weeks' exploration, I became aware of some cases where that specific model was not flexible enough.

> ## Reminder About Image Representation  
>  
> What we can already see in last weeks exploration: The screenshot is represented as a set of pixels, each with a two-dimensional location and a value. This pixel value is composed of a numeric intensity for each of the three color channels red, green and blue.  
> In the type [`DecodeBMPImageResult`](./../2019-07-04.read-screenshot-from-file-and-configure-image-search/app/src/DecodeBMPImage.elm), the two-dimensional location of the pixel is modeled implicitly, as the index of the pixel in the list `pixelsLeftToRightTopToBottom` combined with the image property `bitmapWidthInPixels`.

## Initial Idea

The simplest way I found so far for this testing process:

+ Start from a test implementation. This is simply a bot code which we can run like any other bot, by specifying the `bot-source` location.
+ This template bot code contains all the functionality to load example images and render results from image processing to make review easy. It also contains a function which is responsible for the image processing part.
+ To test our own image processing function, we just replace that image processing function in the example bot code by our own, then run this code as usual.

This approach has the advantage that we reuse significant parts of the general bot development process, including the development environment which analysis the code and draws our attention to potential problems. This reuse ensures familiarity and minimizes required learning effort on the bot developers side.

## Implementation

A good outcome of this exploration would be completing a usable version of that bot code template as described above so that bot developers can start using it. To reduce the wait time for bot developers, the initial scope is reduced to contain only essential functionality.

For the image file decoding functionality, we can reuse the implementation `decodeBMPImageFile` from last weeks exploration, as this already maps from a file (`Bytes` type) to an image (`DecodeBMPImageResult` type).

For testing during exploration, I save an example image to a file in this directory here. The example, in this case, is the screenshot from https://github.com/Viir/bots/blob/21e030d9b6d496a0d0b2e02e2eca1bea3dfb91d0/explore/2019-06-26.how-to-take-screenshots/2019-06-26.eve-online-screenshot.jpeg
To ensure the right image file format, I use the same ['save as BMP' process as last week](./../2019-07-04.read-screenshot-from-file-and-configure-image-search/app/tests/DecodeBMPImageTest.elm). To reduce the cost of the image file in the repository, I crop it before adding it here. The resulting file is in `2019-07-11.example-from-eve-online-crop-0.bmp`.

Since we use the bot interfaces for the implementation, I start by copying the code of an existing bot.
